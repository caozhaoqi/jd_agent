import asyncio

import jwt
import json
from fastapi import APIRouter, BackgroundTasks, Depends, HTTPException, status, UploadFile, File
from fastapi.responses import StreamingResponse
from fastapi.security import OAuth2PasswordBearer
from loguru import logger
from pydantic import BaseModel
from sqlmodel import Session, select
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

# --- å†…éƒ¨æ¨¡å—å¯¼å…¥ ---
# 1. æ•°æ®åº“ä¸é‰´æƒ
from app.core.db_auth import get_session, get_password_hash, verify_password, create_access_token, SECRET_KEY, ALGORITHM
from app.core.models import User, ChatSession, ChatMessage, UserProfile
from app.core.stream_manager import init_stream_queue
from app.graph.workflow import app_graph

# 2. Schema æ•°æ®æ¨¡å‹
from app.schemas.interview import JDRequest, InterviewReport

# 3. ä¸šåŠ¡æœåŠ¡é€»è¾‘
from app.services.interview_service import generate_interview_guide
from app.services.memory_service import update_long_term_memory
from app.services.mock_service import run_mock_interview_stream

# 4. æ ¸å¿ƒå·¥å…·ä¸é“¾
from app.core.llm_factory import get_llm
from app.utils.file_parser import parse_resume_file
from app.chains.resume_extractor import extract_resume_features

# ==========================================
# åˆå§‹åŒ– Router ä¸ Security
# ==========================================
router = APIRouter()
oauth2_scheme = OAuth2PasswordBearer(tokenUrl="/api/v1/login")


# ==========================================
# ä¾èµ–å‡½æ•° (Dependencies)
# ==========================================
async def get_current_user(token: str = Depends(oauth2_scheme), session: Session = Depends(get_session)):
    """
    è§£æ Token è·å–å½“å‰ç™»å½•ç”¨æˆ·
    """
    try:
        payload = jwt.decode(token, SECRET_KEY, algorithms=[ALGORITHM])
        username: str = payload.get("sub")
        if username is None:
            raise HTTPException(status_code=401, detail="Tokenæ— æ•ˆ")
    except jwt.PyJWTError:
        raise HTTPException(status_code=401, detail="å‡­è¯æ— æ•ˆ")

    user = session.exec(select(User).where(User.username == username)).first()
    if user is None:
        raise HTTPException(status_code=401, detail="ç”¨æˆ·ä¸å­˜åœ¨")
    return user


# ==========================================
# 1. è®¤è¯æ¥å£ (Auth)
# ==========================================
class AuthRequest(BaseModel):
    username: str
    password: str


@router.post("/register")
def register(req: AuthRequest, session: Session = Depends(get_session)):
    if session.exec(select(User).where(User.username == req.username)).first():
        raise HTTPException(status_code=400, detail="ç”¨æˆ·åå·²å­˜åœ¨")

    user = User(username=req.username, hashed_password=get_password_hash(req.password))
    session.add(user)
    session.commit()
    return {"msg": "æ³¨å†ŒæˆåŠŸ"}


@router.post("/login")
def login(req: AuthRequest, session: Session = Depends(get_session)):
    user = session.exec(select(User).where(User.username == req.username)).first()
    if not user or not verify_password(req.password, user.hashed_password):
        raise HTTPException(status_code=400, detail="ç”¨æˆ·åæˆ–å¯†ç é”™è¯¯")

    token = create_access_token({"sub": user.username})
    return {"access_token": token, "token_type": "bearer"}


# ==========================================
# 2. ç®€å†ä¸Šä¼ æ¥å£ (Resume)
# ==========================================
@router.post("/upload-resume")
async def upload_resume(
        file: UploadFile = File(...),
        user: User = Depends(get_current_user),
        db: Session = Depends(get_session)
):
    """
    ä¸Šä¼ ç®€å† -> è§£ææ–‡æœ¬ -> LLMæå–ç”»åƒ -> å­˜å…¥é•¿æœŸè®°å¿†
    """
    # 1. è§£ææ–‡ä»¶ (æ”¯æŒ PDF/DOCX/TXT)
    resume_text = await parse_resume_file(file)

    # 2. è°ƒç”¨ LLM æå–å…³é”®ä¿¡æ¯
    facts = await extract_resume_features(resume_text)

    if not facts:
        return {"msg": "ç®€å†è§£æå®Œæˆï¼Œä½†æœªæå–åˆ°æœ‰æ•ˆä¿¡æ¯", "count": 0}

    # 3. å­˜å…¥æ•°æ®åº“ (UserProfile)
    count = 0
    for fact in facts:
        # æŸ¥é‡ï¼šé¿å…é‡å¤å†™å…¥å®Œå…¨ä¸€æ ·çš„ä¿¡æ¯
        exists = db.exec(
            select(UserProfile)
            .where(UserProfile.user_id == user.id)
            .where(UserProfile.content == fact.content)
        ).first()

        if not exists:
            new_profile = UserProfile(
                user_id=user.id,
                category=f"resume_{fact.category}",  # æ ‡è®°æ¥æºä¸ºç®€å†
                content=fact.content
            )
            db.add(new_profile)
            count += 1

    db.commit()

    return {
        "msg": "ç®€å†è§£ææˆåŠŸï¼å·²æ›´æ–°ä¸ªäººç”»åƒã€‚",
        "extracted_facts": [f.content for f in facts],
        "new_entries": count
    }


# ==========================================
# 3. å†å²è®°å½•æ¥å£ (History)
# ==========================================
@router.get("/history/sessions")
def get_sessions(user: User = Depends(get_current_user), session: Session = Depends(get_session)):
    """è·å–å½“å‰ç”¨æˆ·çš„æ‰€æœ‰ä¼šè¯åˆ—è¡¨ (å€’åº)"""
    statement = select(ChatSession).where(ChatSession.user_id == user.id).order_by(ChatSession.id.desc())
    return session.exec(statement).all()


@router.get("/history/messages/{session_id}")
def get_messages(session_id: int, user: User = Depends(get_current_user), session: Session = Depends(get_session)):
    """è·å–æŒ‡å®šä¼šè¯çš„è¯¦ç»†æ¶ˆæ¯"""
    # éªŒè¯ session æ˜¯å¦å±äºè¯¥ç”¨æˆ·
    chat = session.get(ChatSession, session_id)
    if not chat or chat.user_id != user.id:
        raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")
    return chat.messages


# ==========================================
# 4. æ ¸å¿ƒç”Ÿæˆæ¥å£ (Core Logic)
# ==========================================
@router.post("/generate-guide", response_model=InterviewReport)
async def create_guide(
        request: JDRequest,
        background_tasks: BackgroundTasks,
        user: User = Depends(get_current_user),
        db: Session = Depends(get_session),
):
    # 1. ç”ŸæˆæŠ¥å‘Š
    report = await generate_interview_guide(request, db, user.id)

    # 2. å­˜åº“
    try:
        title = f"{report.meta.company_name} é¢è¯•å‡†å¤‡" if report.meta.company_name else "å²—ä½ JD åˆ†æ"
        new_session = ChatSession(title=title, user_id=user.id)
        db.add(new_session)
        db.commit()
        db.refresh(new_session)

        # ä¿å­˜æ¶ˆæ¯è®°å½•
        db.add(ChatMessage(session_id=new_session.id, role="user", content=request.jd_text))
        db.add(ChatMessage(session_id=new_session.id, role="assistant", content=report.model_dump_json()))
        db.commit()

        # âœ… å…³é”®ä¿®æ”¹ï¼šæŠŠ ID å¡å›æŠ¥å‘Šé‡Œï¼Œä¼ ç»™å‰ç«¯
        report.session_id = new_session.id

    except Exception as e:
        logger.error(f"âŒ [DB Error] {e}")

    # 3. æ›´æ–°é•¿æœŸè®°å¿†
    background_tasks.add_task(update_long_term_memory, db, user.id, f"Userä¸Šä¼ äº†JD: {request.jd_text}")

    return report

# ==========================================
# 5. æµå¼å“åº”æ¥å£ (Streaming)
# ==========================================
@router.post("/stream/system-design")
async def stream_system_design(tech_stack: str, topic: str):
    """
    æµå¼ç”Ÿæˆç³»ç»Ÿè®¾è®¡é¢˜ç­”æ¡ˆ (æ‰“å­—æœºæ•ˆæœ)
    """
    llm = get_llm(temperature=0.7)

    prompt = ChatPromptTemplate.from_template(
        "è¯·åŸºäº {tech_stack} æŠ€æœ¯æ ˆï¼Œè¯¦ç»†è®¾è®¡ä¸€ä¸ª {topic} ç³»ç»Ÿã€‚è¯·åŒ…å«æ¶æ„å›¾æè¿°ã€æ•°æ®åº“é€‰å‹å’Œæ ¸å¿ƒéš¾ç‚¹ã€‚"
    )

    chain = prompt | llm | StrOutputParser()

    async def generate_stream():
        async for chunk in chain.astream({"tech_stack": tech_stack, "topic": topic}):
            yield f"data: {chunk}\n\n"
        yield "data: [DONE]\n\n"

    return StreamingResponse(
        generate_stream(),
        media_type="text/event-stream"
    )


@router.post("/stream/mock-interview")
async def stream_mock_interview(request: JDRequest):
    """
    å¼€å¯ä¸€åœº AI äº’åšçš„æ¨¡æ‹Ÿé¢è¯• (æµå¼è¿”å›)
    """
    return StreamingResponse(
        run_mock_interview_stream(request.jd_text, rounds=3),
        media_type="text/event-stream"
    )


class ChatRequest(BaseModel):
    session_id: int
    content: str


@router.post("/chat/stream")
async def stream_chat(
        req: ChatRequest,
        db: Session = Depends(get_session)
):
    """
    é€šç”¨å¤šè½®å¯¹è¯æµå¼æ¥å£ (æ”¯æŒæ¨¡æ‹Ÿé¢è¯•åç»­çš„è¿½é—®)
    """
    # 1. éªŒè¯ä¼šè¯
    session = db.get(ChatSession, req.session_id)
    if not session:
        raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")

    # 2. ä¿å­˜ç”¨æˆ·çš„æ–°å›å¤åˆ°æ•°æ®åº“
    user_msg = ChatMessage(session_id=req.session_id, role="user", content=req.content)
    db.add(user_msg)
    db.commit()

    # 3. å‡†å¤‡å†å²ä¸Šä¸‹æ–‡ (Context)
    # å–æœ€è¿‘ 10 æ¡è®°å½•ï¼Œé˜²æ­¢ Token çˆ†ç‚¸
    recent_msgs = session.messages[-10:]

    # 4. æ„å»º Prompt
    # å¦‚æœæ˜¯æ¨¡æ‹Ÿé¢è¯•æ¨¡å¼ï¼Œç³»ç»Ÿæç¤ºè¯éœ€è¦ä¿æŒâ€œé¢è¯•å®˜â€äººè®¾
    # è¿™é‡Œåšä¸€ä¸ªç®€å•çš„åˆ¤æ–­ï¼šå¦‚æœæ ‡é¢˜åŒ…å«"é¢è¯•"ï¼Œå°±åŠ å¼ºé¢è¯•å®˜äººè®¾
    last_user_msg = req.content

    system_prompt = "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ AI æ±‚èŒåŠ©æ‰‹ï¼Œè´Ÿè´£è§£ç­”ç”¨æˆ·çš„æŠ€æœ¯é—®é¢˜ã€‚"

    # å¦‚æœç”¨æˆ·è§¦å‘äº†å¼€å§‹é¢è¯•çš„å…³é”®è¯
    if "æ¨¡æ‹Ÿé¢è¯•" in last_user_msg or "å¼€å§‹é¢è¯•" in last_user_msg:
        system_prompt = """
            ä½ ç°åœ¨æ˜¯ã€é¢è¯•å®˜æ¨¡å¼ã€‘ã€‚
            è¯·åŸºäºè¯¥ä¼šè¯çš„ä¸Šä¸‹æ–‡ï¼ˆJD å’Œ ç®€å†ï¼‰ï¼Œå‘å€™é€‰äººæå‡ºä¸€ä¸ªå…·ä½“çš„é¢è¯•é—®é¢˜ã€‚
            è¦æ±‚ï¼š
            1. æ¯æ¬¡åªé—®ä¸€ä¸ªé—®é¢˜ï¼Œä¸è¦å †ç Œã€‚
            2. é—®é¢˜è¦çŠ€åˆ©ã€å…·ä½“ï¼Œè€ƒå¯ŸæŠ€æœ¯æ·±åº¦ã€‚
            3. ç­‰å¾…ç”¨æˆ·å›ç­”åï¼Œå†è¿›è¡Œè¿½é—®æˆ–ç‚¹è¯„ã€‚
            """
    elif "é¢è¯•" in session.title:
        # å¦‚æœå·²ç»åœ¨é¢è¯•ä¼šè¯ä¸­ï¼Œä¿æŒä¸¥å‰
        system_prompt = "ä½ æ˜¯ä¸€åä¸¥å‰ä½†ä¸“ä¸šçš„é¢è¯•å®˜ã€‚è¯·æ ¹æ®æ±‚èŒè€…çš„å›ç­”è¿›è¡Œè¿½é—®ï¼Œè€ƒå¯Ÿå…¶æŠ€æœ¯æ·±åº¦ã€‚"

    # LangChain æ¶ˆæ¯æ„å»º
    from langchain_core.messages import SystemMessage, HumanMessage, AIMessage
    lc_messages = [SystemMessage(content=system_prompt)]

    for m in recent_msgs:
        if m.role == "user":
            lc_messages.append(HumanMessage(content=m.content))
        else:
            lc_messages.append(AIMessage(content=m.content))

    # 5. è°ƒç”¨ LLM
    llm = get_llm(temperature=0.7, streaming=True)
    chain = llm | StrOutputParser()

    # 6. æµå¼ç”Ÿæˆå¹¶(æš‚å­˜)ç”¨äºåç»­ä¿å­˜
    # æ³¨æ„ï¼šåœ¨æµå¼å“åº”ä¸­ä¿å­˜ AI å›å¤åˆ°æ•°æ®åº“æ¯”è¾ƒå¤æ‚ï¼Œ
    # ç®€å•åšæ³•æ˜¯å‰ç«¯æ¥æ”¶å®Œåå†è°ƒä¸ª API ä¿å­˜ï¼Œæˆ–è€…ç”± BackgroundTask èšåˆã€‚
    # è¿™é‡Œä¸ºäº†æ¼”ç¤ºæµç•…æ€§ï¼Œæˆ‘ä»¬å…ˆåªåšæµå¼è¾“å‡ºï¼ŒAI å›å¤çš„â€œå…¥åº“â€é€»è¾‘ç•¥è¿‡ï¼Œ
    # æˆ–è€…ä½ å¯ä»¥ä½¿ç”¨ä¸€ä¸ªå›è°ƒå‡½æ•°åœ¨ç”Ÿæˆç»“æŸåä¿å­˜ã€‚

    async def generate_and_stream():
        full_response = ""
        async for chunk in chain.astream(lc_messages):
            full_response += chunk
            yield f"data: {chunk}\n\n"

        # æµç»“æŸåï¼Œä¿å­˜ AI å›å¤åˆ°æ•°æ®åº“ (è¡¥å…¨è®°å½•)
        # æ³¨æ„ï¼šè¿™é‡Œåœ¨ç”Ÿæˆå™¨é‡Œæ“ä½œ DB éœ€è¦å°å¿ƒ Session ä½œç”¨åŸŸï¼Œç®€å•åœºæ™¯ä¸‹ç›´æ¥ç”¨å³å¯
        try:
            ai_msg = ChatMessage(session_id=req.session_id, role="assistant", content=full_response)
            db.add(ai_msg)
            db.commit()
        except Exception as e:
            logger.debug(f"Error saving AI response: {e}")

        yield "data: [DONE]\n\n"

    return StreamingResponse(
        generate_and_stream(),
        media_type="text/event-stream"
    )



# ==========================================
# 6. è¯­éŸ³äº¤äº’æ¥å£ (ASR & TTS)
# ==========================================

from fastapi.responses import Response


# app/api/endpoints.py

@router.post("/audio/transcribe")
async def transcribe_audio(file: UploadFile = File(...)):
    """
    ASR: è¯­éŸ³è½¬æ–‡å­— (é€‚é… SiliconFlow SenseVoiceSmall)
    """
    from openai import OpenAI
    from app.core.config import settings

    # 1. åˆå§‹åŒ–å®¢æˆ·ç«¯
    # ç¡®ä¿ä½¿ç”¨çš„æ˜¯æ”¯æŒ Audio çš„ API Key (å¦‚ SiliconFlow)
    client = OpenAI(
        api_key=settings.AUDIO_API_KEY or settings.OPENAI_API_KEY,
        base_url=settings.AUDIO_API_BASE or settings.OPENAI_API_BASE
    )

    try:
        # 2. è¯»å–æ–‡ä»¶äºŒè¿›åˆ¶å†…å®¹
        file_content = await file.read()

        # 3. æ„é€  OpenAI SDK è®¤å¯çš„æ–‡ä»¶å…ƒç»„ (å…³é”®ä¿®å¤!)
        # æ ¼å¼: (æ–‡ä»¶å, äºŒè¿›åˆ¶æ•°æ®, MIMEç±»å‹)
        # å¦‚æœ file.filename ä¸ºç©ºï¼Œå¼ºåˆ¶ç»™ä¸€ä¸ª "audio.wav"
        filename = file.filename or "audio.wav"

        # å¼ºåˆ¶æŒ‡å®š MIME ç±»å‹ï¼ŒSiliconFlow å¯¹æ­¤å¾ˆæ•æ„Ÿ
        file_tuple = (filename, file_content, "audio/wav")

        # 4. è°ƒç”¨ API
        transcript = client.audio.transcriptions.create(
            model=settings.ASR_MODEL,  # ç¡®ä¿ .env æ˜¯ FunAudioLLM/SenseVoiceSmall
            file=file_tuple,  # ä¼ å…¥æ„é€ å¥½çš„å…ƒç»„
            temperature=0.0
        )
        return {"text": transcript.text}

    except Exception as e:
        logger.debug(f"âŒ ASR Error: {e}")
        return {"text": "", "error": str(e)}


@router.post("/audio/tts_old")
async def text_to_speech(text: str):
    """
    TTS: æ–‡å­—è½¬è¯­éŸ³
    """
    from openai import OpenAI
    from app.core.config import settings

    client = OpenAI(
        api_key=settings.OPENAI_API_KEY,
        base_url=settings.OPENAI_API_BASE
    )

    try:
        # è°ƒç”¨ TTS æ¨¡å‹ (tts-1 æˆ– tts-1-hd)
        response = client.audio.speech.create(
            # model="tts-1",
            # voice="alloy",  # å¯é€‰: alloy, echo, fable, onyx, nova, shimmer
            model=settings.TTS_MODEL,
            voice="alex",  # æ³¨æ„ï¼šFishSpeech çš„ voice å‚æ•°å¯èƒ½ä¸åŒï¼Œå‚è€ƒå®˜æ–¹æ–‡æ¡£
            # input=text
            input=text
        )

        # ç›´æ¥è¿”å›äºŒè¿›åˆ¶éŸ³é¢‘æµ
        return Response(
            content=response.content,
            media_type="audio/mpeg"
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# app/api/endpoints.py

@router.post("/agent/feedback")
async def agent_feedback(thread_id: str, feedback: str, action: str = "retry"):
    """
    ç”¨æˆ·å¯¹ AI æš‚åœçš„ä»»åŠ¡è¿›è¡Œå¹²é¢„
    action: "approve" (å¼ºåˆ¶é€šè¿‡) | "retry" (å¸¦æ„è§é‡è¯•)
    """
    config = {"configurable": {"thread_id": thread_id}}

    if action == "approve":
        # å¼ºåˆ¶æ›´æ–°çŠ¶æ€ï¼šæŠŠåˆ†æ•°æ”¹æˆ 100ï¼Œè¿™æ ·è·¯ç”±å°±ä¼šé€šè¿‡
        app_graph.update_state(config, {"quality_score": 100, "human_feedback": "å¼ºåˆ¶é€šè¿‡"})
    else:
        # æ³¨å…¥ç”¨æˆ·çš„ä¿®æ”¹æ„è§
        app_graph.update_state(config, {"human_feedback": feedback})

    # æ¢å¤æ‰§è¡Œ (Resume)
    # è¿™é‡Œçš„ None è¡¨ç¤ºç»§ç»­æ‰§è¡Œä¸‹ä¸€æ­¥ (å³è¿›å…¥ tech_lead é‡å†™)
    async for event in app_graph.astream(None, config=config):
        pass

    return {"status": "Resumed"}


@router.post("/stream/generate-guide")  # æ–°å¢ä¸€ä¸ªæµå¼æ¥å£
async def stream_generate_guide(
        request: JDRequest,
        user: User = Depends(get_current_user),
        db: Session = Depends(get_session)
):
    """
    L5 çº§ Agent æµå¼ç”Ÿæˆæ¥å£ (æ”¯æŒ DeepSeek æ€è€ƒè¿‡ç¨‹)
    """

    # 1. åˆå§‹åŒ–é˜Ÿåˆ— (ContextVar ä¼šè‡ªåŠ¨ç»‘å®šåˆ°å½“å‰ task)
    queue = init_stream_queue()

    # 2. å®šä¹‰åå°è¿è¡Œä»»åŠ¡
    async def run_graph_background():
        try:
            initial_state = {
                "jd_text": request.jd_text,
                "user_id": user.id,
                "iteration_count": 0,
                "tech_stack": [],
                "years_required": ""
            }

            thread_id = f"user_{user.id}_job_{hash(request.jd_text)}"
            config = {"configurable": {"thread_id": thread_id}}

            # è¿è¡Œ Graph
            final_state = await app_graph.ainvoke(initial_state, config=config)

            # è¿è¡Œç»“æŸï¼ŒæŠŠæœ€ç»ˆç»“æœæ„é€ æˆ token ç±»å‹å‘å‡ºå»
            # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬æŠŠæ•´ä¸ª Report æ‰“åŒ…æˆä¸€ä¸ª JSON å­—ç¬¦ä¸²å‘è¿‡å»
            # å‰ç«¯æ”¶åˆ° type='result' æ—¶ï¼Œç›´æ¥æ¸²æŸ“æœ€ç»ˆæŠ¥å‘Š
            from app.schemas.interview import InterviewReport, JDMetaData

            # ... ç»„è£… Report é€»è¾‘ (åŒ interview_service) ...
            # ä¸ºäº†æ¼”ç¤ºï¼Œç®€å•ç»„è£…
            final_report = {
                "meta": {
                    "company_name": final_state.get("company_name"),
                    "tech_stack": final_state.get("tech_stack"),
                    "years_required": final_state.get("years_required"),
                    "soft_skills": []
                },
                "tech_questions": final_state.get("tech_questions"),
                "hr_questions": final_state.get("hr_questions"),
                "company_analysis": final_state.get("company_info")
            }

            await queue.put({
                "type": "result",  # æ ‡è®°ä¸ºæœ€ç»ˆç»“æœ
                "content": json.dumps(final_report)
            })

        except Exception as e:
            await queue.put({"type": "error", "content": str(e)})
        finally:
            # å‘é€ç»“æŸä¿¡å·
            await queue.put(None)

            # 3. å¯åŠ¨åå°ä»»åŠ¡

    task = asyncio.create_task(run_graph_background())

    # 4. å®šä¹‰ç”Ÿæˆå™¨ (æ¶ˆè´¹é˜Ÿåˆ—)
    async def event_generator():
        while True:
            # ç­‰å¾…é˜Ÿåˆ—æ¶ˆæ¯
            data = await queue.get()

            if data is None:  # ç»“æŸä¿¡å·
                yield "data: [DONE]\n\n"
                break

            # å‘é€ SSE
            yield f"data: {json.dumps(data)}\n\n"

    return StreamingResponse(event_generator(), media_type="text/event-stream")


import platform
import subprocess
import tempfile
import os
import uuid
import pyttsx3  # ç”¨äº Windows/Linux
from fastapi.responses import Response

# é¢„åˆå§‹åŒ– Windows/Linux çš„å¼•æ“ (Mac ä¸ç”¨è¿™ä¸ª)
try:
    if platform.system() != "Darwin":
        engine = pyttsx3.init()
except Exception as e:
    logger.error(f"âš ï¸ pyttsx3 init failed: {e}")


@router.post("/audio/tts")
async def text_to_speech(text: str):
    """
    è·¨å¹³å° TTS æ¥å£ (å®Œå…¨ç¦»çº¿ï¼Œé›¶å»¶è¿Ÿ)
    - macOS: è°ƒç”¨ 'say' å‘½ä»¤ -> .m4a
    - Windows/Linux: è°ƒç”¨ pyttsx3 -> .wav
    """
    if not text or not text.strip():
        raise HTTPException(status_code=400, detail="æ–‡æœ¬ä¸ºç©º")

    # è·å–å½“å‰æ“ä½œç³»ç»Ÿåç§° ('Darwin', 'Windows', 'Linux')
    system_os = platform.system()

    # å®šä¹‰ä¸´æ—¶æ–‡ä»¶è·¯å¾„
    unique_id = uuid.uuid4()
    temp_dir = tempfile.gettempdir()

    try:
        audio_data = None
        mime_type = ""
        output_path = ""

        # ============================
        # ğŸ æ–¹æ¡ˆ A: macOS (Darwin)
        # ============================
        if system_os == "Darwin":
            output_path = os.path.join(temp_dir, f"tts_{unique_id}.m4a")
            mime_type = "audio/mp4"  # m4a å±äº mp4 å®¹å™¨

            # ä½¿ç”¨ macOS åŸç”Ÿ say å‘½ä»¤
            process = subprocess.run(
                ["say", "-o", output_path, text],
                capture_output=True,
                text=True
            )
            if process.returncode != 0:
                raise Exception(f"Mac TTS failed: {process.stderr}")

        # ============================
        # ğŸªŸ/ğŸ§ æ–¹æ¡ˆ B: Windows / Linux
        # ============================
        else:
            output_path = os.path.join(temp_dir, f"tts_{unique_id}.wav")
            mime_type = "audio/wav"

            # ä½¿ç”¨ pyttsx3 (SAPI5 / eSpeak)
            # æ³¨æ„ï¼špyttsx3 æ˜¯åŒæ­¥é˜»å¡çš„ï¼Œé«˜å¹¶å‘å»ºè®®æ”¾å…¥çº¿ç¨‹æ± ï¼Œå•äººä½¿ç”¨æ— æ‰€è°“
            engine.save_to_file(text, output_path)
            engine.runAndWait()

        # ============================
        # 3. è¯»å–å¹¶æ¸…ç†
        # ============================
        if not os.path.exists(output_path) or os.path.getsize(output_path) == 0:
            raise Exception("éŸ³é¢‘æ–‡ä»¶ç”Ÿæˆå¤±è´¥")

        with open(output_path, "rb") as f:
            audio_data = f.read()

        # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
        os.remove(output_path)

        return Response(content=audio_data, media_type=mime_type)

    except Exception as e:
        logger.debug(f"âŒ [TTS Error] OS: {system_os} | Error: {e}")
        # å°è¯•æ¸…ç†æ®‹ä½™æ–‡ä»¶
        if 'output_path' in locals() and os.path.exists(output_path):
            os.remove(output_path)
        raise HTTPException(status_code=500, detail=f"TTSç”Ÿæˆå¤±è´¥: {str(e)}")