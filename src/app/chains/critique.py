from typing import List
from langchain.prompts import ChatPromptTemplate
from langchain.output_parsers import PydanticOutputParser
from pydantic import BaseModel
from app.core.llm_factory import get_llm
from app.schemas.interview import InterviewQuestion
from app.utils.logger import logger


# è¾…åŠ©æ¨¡å‹
class QuestionList(BaseModel):
    questions: List[InterviewQuestion]


async def critique_tech_questions_async(
        original_questions: List[InterviewQuestion],
        level: str
) -> List[InterviewQuestion]:
    """
    åæ€ç¯èŠ‚ï¼šæ£€æŸ¥ç”Ÿæˆçš„é¢˜ç›®æ˜¯å¦ç¬¦åˆèŒçº§è¦æ±‚ï¼Œå¦‚æœä¸ç¬¦åˆåˆ™ä¿®æ”¹ã€‚
    """
    logger.info(f"ğŸ¤” [Reflection] Critiquing {len(original_questions)} questions for level: {level}...")

    # 1. å‡†å¤‡æ•°æ®ï¼šæŠŠå¯¹è±¡è½¬æˆæ–‡æœ¬å–‚ç»™ LLM
    questions_text = "\n".join([f"Q: {q.question}\nA: {q.reference_answer}" for q in original_questions])

    # 2. è®¾ç½® LLM (å»ºè®®ç”¨ Smart æ¨¡å‹ï¼Œå¦‚ GPT-4/DeepSeek-V3ï¼Œæ¸©åº¦ç¨ä½)
    llm = get_llm(temperature=0.3)
    parser = PydanticOutputParser(pydantic_object=QuestionList)

    # 3. ç¼–å†™â€œåæ€â€ Prompt
    prompt = ChatPromptTemplate.from_template(
        """
        ä½ æ˜¯ä¸€ä¸ªä¸¥å‰çš„æŠ€æœ¯é¢è¯•å®˜ä¸»ç®¡ã€‚è¯·å®¡æ ¸ä»¥ä¸‹åˆçº§é¢è¯•å®˜ç”Ÿæˆçš„é¢è¯•é¢˜ã€‚

        ã€ç›®æ ‡å€™é€‰äººèŒçº§ã€‘ï¼š{level}

        ã€å¾…å®¡æ ¸é¢˜ç›®ã€‘ï¼š
        {questions_text}

        ã€å®¡æ ¸æ ‡å‡†ã€‘ï¼š
        1. éš¾åº¦åŒ¹é…ï¼šå¦‚æœå€™é€‰äººæ˜¯é«˜çº§/èµ„æ·±ï¼Œé¢˜ç›®ä¸èƒ½é—®åŸºç¡€è¯­æ³•ï¼Œå¿…é¡»é—®åº•å±‚åŸç†æˆ–æ¶æ„è®¾è®¡ã€‚
        2. å‡†ç¡®æ€§ï¼šå‚è€ƒå›ç­”å¿…é¡»å‡†ç¡®æ— è¯¯ã€‚
        3. æ·±åº¦ï¼šé¢˜ç›®ä¸èƒ½å¤ªå®½æ³›ï¼Œè¦æœ‰å…·ä½“çš„è€ƒå¯Ÿç‚¹ã€‚

        ã€ä»»åŠ¡ã€‘ï¼š
        - å¦‚æœé¢˜ç›®è´¨é‡åˆæ ¼ï¼Œç›´æ¥ä¿ç•™åŸé¢˜ã€‚
        - **å¦‚æœé¢˜ç›®å¤ªç®€å•æˆ–æœ‰é€»è¾‘é”™è¯¯ï¼Œè¯·é‡å†™è¯¥é¢˜ç›®å’Œç­”æ¡ˆï¼Œä½¿å…¶æ›´å…·æŒ‘æˆ˜æ€§ã€‚**
        - ä¿æŒé¢˜ç›®æ•°é‡ä¸å˜ã€‚

        è¯·ä¸¥æ ¼æŒ‰ç…§ JSON æ ¼å¼è¾“å‡ºä¿®æ­£åçš„é¢˜ç›®åˆ—è¡¨:
        {format_instructions}
        """
    )

    chain = prompt | llm | parser

    try:
        # 4. æ‰§è¡Œåæ€
        result = await chain.ainvoke({
            "level": level,
            "questions_text": questions_text,
            "format_instructions": parser.get_format_instructions()
        })
        logger.success("âœ¨ [Reflection] Questions refined successfully.")
        return result.questions

    except Exception as e:
        logger.warning(f"âš ï¸ [Reflection] Critique failed, returning original questions. Error: {e}")
        # å¦‚æœåæ€æ­¥éª¤æŒ‚äº†ï¼ˆæ¯”å¦‚ Token è¶…é™ï¼‰ï¼Œä¸ºäº†ç³»ç»Ÿç¨³å®šæ€§ï¼Œé™çº§è¿”å›åŸé¢˜
        return original_questions