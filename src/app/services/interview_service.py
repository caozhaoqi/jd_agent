import asyncio
from app.schemas.interview import InterviewReport, JDRequest
from app.chains.jd_parser import parse_jd_async
from app.chains.tech_gen import generate_tech_async
from app.chains.hr_gen import generate_hr_async
from app.chains.company_research import research_company
from app.chains.critique import critique_tech_questions_async  # å¯¼å…¥åæ€é“¾
from app.utils.logger import logger
from app.core.knowledge_base import kb_engine
from sqlmodel import Session
from app.core.memory import get_recent_chat_history  # å¯¼å…¥çŸ­æœŸè®°å¿†å·¥å…·
# ğŸ”´ å¯¼å…¥é•¿æœŸè®°å¿†å·¥å…· (å¦‚æœæ²¡æœ‰è¯·ç¡®ä¿ä¹‹å‰å·²åˆ›å»º app/services/memory_service.py)
from app.services.memory_service import get_user_profile_str


async def generate_interview_guide(
        request: JDRequest,
        db: Session,  # æ¥æ”¶æ•°æ®åº“ Session
        user_id: int  # æ¥æ”¶å½“å‰ç”¨æˆ· ID
) -> InterviewReport:
    logger.info("ğŸ¤– [Service] Starting generation with Memory & RAG & Reflection...")

    try:
        # 1. è·å–è®°å¿† (Memory)
        # çŸ­æœŸè®°å¿† (æœ€è¿‘å¯¹è¯)
        chat_history = get_recent_chat_history(db, user_id)
        # ğŸ”´ é•¿æœŸè®°å¿† (ç”¨æˆ·ç”»åƒ)
        ltm_profile = get_user_profile_str(db, user_id)

        logger.info(f"ğŸ§  [Memory] Loaded {len(chat_history)} recent msgs. Profile len: {len(ltm_profile)}")

        # 2. è§£æ JD
        jd_meta = await parse_jd_async(request.jd_text)

        # 3. RAG æ£€ç´¢ (æŸ¥åšå®¢)
        logger.info(f"ğŸ” [RAG] Searching blog for: {jd_meta.tech_stack}")
        query_text = " ".join(jd_meta.tech_stack)
        kb_result = await kb_engine.search(query_text, top_k=3)
        blog_context = kb_result["context"]
        blog_sources = kb_result["sources"]

        if blog_sources:
            logger.info(f"ğŸ“š [RAG] Hit knowledge: {blog_sources}")

        # 4. ç¬¬ä¸€è½®ç”Ÿæˆ (Drafting Phase)
        # ğŸ”´ æ ¸å¿ƒä¿®å¤ï¼šè¿™é‡Œå¿…é¡»ä¼ å…¥ user_profile å‚æ•°ï¼
        task_tech_draft = generate_tech_async(
            tech_stack=jd_meta.tech_stack,
            level=jd_meta.years_required,
            kb_context=blog_context,
            chat_history=chat_history,  # ä¼ å…¥çŸ­æœŸè®°å¿†
            user_profile=ltm_profile  # ğŸ”´ ä¼ å…¥é•¿æœŸè®°å¿† (ä¿®å¤ KeyError)
        )

        company_name = getattr(jd_meta, "company_name", "")
        task_research = research_company(company_name)

        # å¹¶å‘æ‰§è¡Œåˆç¨¿ç”Ÿæˆå’ŒèƒŒè°ƒ
        tech_qs_draft, company_info = await asyncio.gather(task_tech_draft, task_research)

        # 5. åæ€ç¯èŠ‚ (Reflection Phase)
        final_tech_qs = await critique_tech_questions_async(
            original_questions=tech_qs_draft,
            level=jd_meta.years_required
        )

        # 6. ç”Ÿæˆ HR é¢˜
        hr_qs = await generate_hr_async(jd_meta.soft_skills, company_info)

        # 7. è¿”å›
        return InterviewReport(
            meta=jd_meta,
            tech_questions=final_tech_qs,
            hr_questions=hr_qs,
            system_design_question=None,
            reference_sources=blog_sources
        )

    except Exception as e:
        logger.error(f"âŒ [Service Error]: {str(e)}")
        raise e