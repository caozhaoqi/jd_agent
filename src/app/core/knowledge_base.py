import os
from typing import List, Dict
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from app.utils.logger import logger

# ä½ çš„å‘é‡åº“è·¯å¾„ (è¯·ç¡®ä¿ build_blog_kb.py å·²ç»è¿è¡Œè¿‡å¹¶åœ¨æ ¹ç›®å½•ç”Ÿæˆäº†æ­¤æ–‡ä»¶å¤¹)
# DB_PATH = "blog_faiss_index"
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.dirname(CURRENT_DIR)))
DB_PATH = os.path.join(PROJECT_ROOT, "blog_faiss_index")

class BlogKnowledgeBase:
    _instance = None

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(BlogKnowledgeBase, cls).__new__(cls)
            cls._instance._initialize()
        return cls._instance

    def _initialize(self):
        """åˆå§‹åŒ–åŠ è½½æ¨¡å‹å’Œå‘é‡åº“ (å•ä¾‹æ¨¡å¼ï¼ŒåªåŠ è½½ä¸€æ¬¡)"""
        logger.info("ğŸ“š [KB] Initializing Blog Knowledge Base...")
        try:
            # 1. åˆå§‹åŒ– Embedding (ä½¿ç”¨å›½å†…é•œåƒé€»è¾‘)
            os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'
            self.embeddings = HuggingFaceEmbeddings(
                model_name="BAAI/bge-small-zh-v1.5",
                model_kwargs={'device': 'cpu'},
                encode_kwargs={'normalize_embeddings': True}
            )

            # 2. åŠ è½½ FAISS
            if os.path.exists(DB_PATH):
                self.vector_store = FAISS.load_local(
                    DB_PATH,
                    self.embeddings,
                    allow_dangerous_deserialization=True
                )
                logger.success("âœ… [KB] Vector Store loaded successfully.")
            else:
                logger.warning(f"âš ï¸ [KB] Index not found at {DB_PATH}. RAG disabled.")
                self.vector_store = None
        except Exception as e:
            logger.error(f"âŒ [KB] Init failed: {e}")
            self.vector_store = None

    async def search(self, query: str, top_k: int = 3) -> Dict[str, str]:
        """
        æ£€ç´¢ç›¸å…³æ–‡æ¡£
        è¿”å›æ ¼å¼: {"context": "æ–‡æ¡£å†…å®¹...", "sources": ["æ–‡ç« A.md", "æ–‡ç« B.md"]}
        """
        if not self.vector_store:
            return {"context": "", "sources": []}

        try:
            # å¼‚æ­¥æ‰§è¡Œæœç´¢ (FAISS æœ¬èº«æ˜¯ CPU å¯†é›†å‹ï¼Œä½†åœ¨ Web æœåŠ¡ä¸­å¾ˆå¿«)
            # è¿™é‡Œç®€å•ç”¨åŒæ­¥è°ƒç”¨ï¼Œå› ä¸º FAISS åœ¨å†…å­˜ä¸­æå¿«
            docs = self.vector_store.similarity_search(query, k=top_k)

            if not docs:
                return {"context": "", "sources": []}

            # æ‹¼æ¥å†…å®¹
            context_parts = []
            sources = set()

            for doc in docs:
                source = doc.metadata.get("source", "æœªçŸ¥æ¥æº")
                sources.add(source)
                context_parts.append(f"---[å¼•ç”¨è‡ª: {source}]---\n{doc.page_content}")

            return {
                "context": "\n\n".join(context_parts),
                "sources": list(sources)
            }
        except Exception as e:
            logger.error(f"âŒ [KB] Search failed: {e}")
            return {"context": "", "sources": []}


# å¯¼å‡ºå•ä¾‹
kb_engine = BlogKnowledgeBase()
